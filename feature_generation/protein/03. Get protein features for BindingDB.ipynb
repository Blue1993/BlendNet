{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7c81124",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import torch\n",
    "import pickle\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from transformers import BertModel, BertTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461d5dbd",
   "metadata": {},
   "source": [
    "### 1. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df02ae6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "IC50_df = pd.read_csv(\"../../input_data/BindingDB/IC50_data.tsv\", sep = \"\\t\")\n",
    "IC50_uniprot_IDs, IC50_uniprot_seqs = IC50_df.iloc[:, 0].values, IC50_df.iloc[:, 3].values\n",
    "\n",
    "Ki_df = pd.read_csv(\"../../input_data/BindingDB/Ki_data.tsv\", sep = \"\\t\")\n",
    "Ki_uniprot_IDs, Ki_uniprot_seqs = Ki_df.iloc[:, 0].values, Ki_df.iloc[:, 3].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a648125d",
   "metadata": {},
   "source": [
    "### 2. Get protein features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dea13f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_info(dataset, uniprot_ids, uniprot_seqs):\n",
    "    protein_seqs_dict = dict()\n",
    "    \n",
    "    for i, s in zip(uniprot_ids, uniprot_seqs):\n",
    "        protein_seqs_dict[i] = s\n",
    "    print(f\"[{dataset}] Uniprot_IDs: {len(protein_seqs_dict)}\")\n",
    "    \n",
    "    return protein_seqs_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "edb2342d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[IC50] Uniprot_IDs: 4347\n",
      "[Ki] Uniprot_IDs: 2431\n"
     ]
    }
   ],
   "source": [
    "IC50_protein_seqs_dict = get_info(\"IC50\", IC50_uniprot_IDs, IC50_uniprot_seqs)\n",
    "Ki_protein_seqs_dict = get_info(\"Ki\", Ki_uniprot_IDs, Ki_uniprot_seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70422658",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at Rostlab/prot_bert were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"Rostlab/prot_bert\", do_lower_case = False)\n",
    "prots_model = BertModel.from_pretrained(\"Rostlab/prot_bert\") \n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "prots_model = prots_model.to(device)\n",
    "prots_model = prots_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2345bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(protein_seqs_dict):\n",
    "    protein_features_dict = dict()\n",
    "    \n",
    "    for PID in list(protein_seqs_dict.keys()):\n",
    "        seqs_example = \" \".join(list(re.sub(r\"[UZOB]\", \"X\", protein_seqs_dict[PID])))\n",
    "\n",
    "        ids = tokenizer.batch_encode_plus([seqs_example], add_special_tokens = True, pad_to_max_length = True)\n",
    "        input_ids = torch.tensor(ids['input_ids']).to(device)\n",
    "        attention_mask = torch.tensor(ids['attention_mask']).to(device) \n",
    "\n",
    "        with torch.no_grad(): \n",
    "            embedding = prots_model(input_ids = input_ids, attention_mask = attention_mask)[0]\n",
    "            embedding = embedding.cpu().numpy()\n",
    "            seq_len = (attention_mask[0] == 1).sum()\n",
    "\n",
    "            if seq_len < 1503:\n",
    "                seq_emd = embedding[0][1:seq_len-1]            \n",
    "\n",
    "            else:\n",
    "                seq_len = 1502\n",
    "                seq_emd = embedding[0][1:seq_len-1]\n",
    "\n",
    "        protein_features_dict[PID] = seq_emd\n",
    "        \n",
    "    return protein_features_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3de4fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "IC50_feature_dict = get_features(IC50_protein_seqs_dict)\n",
    "print(f\"PDBbind features: {len(IC50_feature_dict)}\")\n",
    "with open(\"../../input_data/BindingDB/IC50_protein_features.pkl\", \"wb\") as f:        \n",
    "    pickle.dump(IC50_feature_dict, f) \n",
    "    \n",
    "Ki_feature_dict = get_features(Ki_protein_seqs_dict)\n",
    "print(f\"PDBbind features: {len(Ki_feature_dict)}\")\n",
    "with open(\"../../input_data/BindingDB/Ki_protein_features.pkl\", \"wb\") as f:        \n",
    "    pickle.dump(Ki_feature_dict, f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f7d4dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
